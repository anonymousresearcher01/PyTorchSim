import os
import shlex
import subprocess
import re
import sys
import json
import time
import threading
from pathlib import Path

import torch
import numpy as np

from PyTorchSimFrontend.llvm.llvm_common import LLVMKernelArgs
from PyTorchSimFrontend import extension_config

TORCH_TO_NUMPY = {
    torch.float32: np.float32,
    torch.float64: np.float64,
    torch.int64: np.int64,
    torch.int32: np.int32,
    torch.int16: np.int16,
    torch.int8: np.int8,
    torch.uint8: np.uint8,
    torch.bool: np.uint8,
    torch.bfloat16: np.float16,
}

class FunctionalSimulator():
    def __init__(self, path, key):
        self.path = path
        self.key = key

    def load_tensor(self, arg, arg_name, arg_attribute, path):
        # path = os.path.join(dump_path, arg_name, f'{n_call}.raw')
        with open(path, 'rb') as f:
            np_array = np.fromfile(f, dtype=TORCH_TO_NUMPY[arg.dtype])
            src_tensor = torch.as_strided(torch.from_numpy(np_array), arg.size(), arg.stride())
            arg.copy_(src_tensor.to(dtype=arg.dtype))

    def get_biggest_filename(self, path):
        return len(os.listdir(path))

    def write_arg(self, arg, path, name):
        dump_path = os.path.join(path, name)
        os.makedirs(dump_path, exist_ok=True)
        index = self.get_biggest_filename(dump_path)

        if (isinstance(arg, torch.Tensor)):
            data_path = os.path.join(dump_path, f'{index}.raw')
            tensor = arg.cpu().detach()
            t_arr = tensor.numpy().flatten()
            t_arr.tofile(data_path)
        else:
            assert(0)
        return index

    def dump_args(self, args, arg_attributes, load_path, dump_path):
        array_size = []
        file_path = []
        for (arg_name, arg_attribute), arg in zip(arg_attributes, args):
            size = arg_attribute[2] if arg_attribute[1] != torch.bool else (arg_attribute[2] + 7) // 8
            array_size.append(size)
            if LLVMKernelArgs.is_llvm_arg_in(arg_attribute[0]):
                index = self.write_arg(arg, load_path, arg_name)
                file_path.append(os.path.join(load_path, arg_name, f'{index}.raw'))
            elif LLVMKernelArgs.is_llvm_arg_out(arg_attribute[0]):
                path = os.path.join(dump_path, arg_name)
                os.makedirs(path, exist_ok=True)
                file_path.append(os.path.join(path, f'{self.get_biggest_filename(path)}.raw'))

        return array_size, file_path

    def run_spike(self, args, arg_attributes, runtime_path, binary, vectorlane_size=4, spad_info=None, cleanup=False):
        load_path = runtime_path
        dump_path = runtime_path

        target_binary = os.path.join(self.path, binary)
        objdump = f"riscv64-unknown-elf-objdump -d {target_binary} > {os.path.join(self.path, 'binary.dump')}"
        kernel_start = f"nm {target_binary} | grep 'kernel' | awk 'NR==1 {{print $1}}'"
        kernel_end = f"nm {target_binary} | grep 'kernel' | awk 'NR==1 {{print $1}}' | xargs -I {{}} awk '/{{}}/,0' {os.path.join(self.path, 'binary.dump')} | grep ret | awk 'NR==1 {{print $1}}' | awk '{{gsub(/:$/, \"\"); print}}'"

        subprocess.run(objdump, shell=True)
        kernel_start_addr = subprocess.run(kernel_start, shell=True, stdout=subprocess.PIPE).stdout.strip().decode('utf-8')
        kernel_end_addr = subprocess.run(kernel_end, shell=True, stdout=subprocess.PIPE).stdout.strip().decode('utf-8')

        _, file_path = self.dump_args(args, arg_attributes, load_path, dump_path)
        file_path_str = ' '.join(file_path)

        # Set hardware information
        spad_option = f"-m0x{0x80000000:x}:0x{100<<30:x},0x{spad_info['spad_paddr']:x}:0x{spad_info['spad_size']*vectorlane_size:x} " + \
            f"--scratchpad-base-paddr={spad_info['spad_paddr']} " + \
            f"--scratchpad-base-vaddr={spad_info['spad_vaddr']} " + \
            f"--scratchpad-size={spad_info['spad_size']} "
        vectorlane_option = f"--vectorlane-size={vectorlane_size}"
        kernel_address = f"--kernel-addr={kernel_start_addr}:{kernel_end_addr}"
        base_path= f"--base-path={runtime_path}"
        os.makedirs(os.path.join(runtime_path, "indirect_access"), exist_ok=True)
        os.makedirs(os.path.join(runtime_path, "dma_access"), exist_ok=True)
        run = f'spike --isa rv64gcv --varch=vlen:256,elen:64 {vectorlane_option} {spad_option} {kernel_address} {base_path} /workspace/riscv-pk/build/pk {target_binary} {file_path_str}'

        print("[SpikeSimulator] cmd> ", run)
        run_cmd = shlex.split(run)
        try:
            subprocess.check_call(run_cmd)
        except subprocess.CalledProcessError as e:
            print("[SpikeSimulator] Command failed with exit code", e.returncode)
            print("[SpikeSimulator] Error output:", e.output)
            assert(0)

        for (arg_name, arg_attribute), arg, path in zip(arg_attributes, args, file_path):
            if LLVMKernelArgs.is_llvm_arg_out(arg_attribute[0]):
                self.load_tensor(arg, arg_name, arg_attribute, path)

        if cleanup:
            for path in file_path:
                if os.path.exists(path):
                    os.remove(path)

    @staticmethod
    def get_runtime_dump_path(base_path, prefix="runtime", zfill=4):
        indices = [
            int(match.group(1))
            for d in os.listdir(base_path)
            if (match := re.fullmatch(rf"{prefix}_(\d{{{zfill}}})", d))
        ]

        max_index = max(indices, default=-1)
        next_index = max_index + 1
        folder_name = f"{prefix}_{str(next_index).zfill(zfill)}"
        full_path = os.path.join(base_path, folder_name)

        os.makedirs(full_path)
        return full_path

class CycleSimulator():
    def __init__(self) -> None:
        pass

    def compile_and_simulate(self, target_binary, array_size, vectorlane_size):
        def show_progress():
            i = 0
            while not finished:
                i = (i + 1) % 3
                tail = "." * i + " " * (3-i)
                sys.stdout.write("\r[Gem5Simulator] Simulation is still running." + tail)
                time.sleep(1)
            print("")

        dir_path = os.path.join(os.path.dirname(target_binary), "m5out")
        gem5_cmd = [extension_config.CONFIG_GEM5_PATH, "-d", dir_path, extension_config.CONFIG_GEM5_SCRIPT_PATH, "-c", target_binary, "--vlane", str(vectorlane_size)]
        try:
            # Create progress thread
            is_dryrun = int(os.environ.get('BACKENDSIM_DRYRUN', default=False))
            if not is_dryrun:
                print("[Gem5Simulator] cmd> ", " ".join(gem5_cmd))
                finished = False
                progress_thread = threading.Thread(target=show_progress)
                progress_thread.start()
                output = subprocess.check_output(gem5_cmd, stderr=subprocess.DEVNULL)
                finished = True
                progress_thread.join()
            else:
                output = subprocess.check_output(gem5_cmd, stderr=subprocess.DEVNULL)
        except subprocess.CalledProcessError as e:
            print("[Gem5Simulator] Command failed with exit code", e.returncode)
            print("[Gem5Simulator] Error output:", e.output)
            finished = True
            progress_thread.join()
            assert(0)

        with open(f"{dir_path}/stats.txt", "r") as stat_file:
            raw_list = stat_file.readlines()
            cycle_per_tick = [int(line.split()[1]) for line in raw_list if "system.clk_domain.clock" in line][0]
            cycle_list = [int(line.split()[1]) for line in raw_list if "system.cpu.numCycles" in line]
        cycle_list = cycle_list[:-1]
        return cycle_list

class BackendSimulator():
    BACKEND_RESULT_PATH_KEY = "BACKEND_RESULT_PATH"
    FINISH_STR = "Simulation Finished"
    def __init__(self, backend_path, config_path, vectorlane_size=-1) -> None:
        self.base_dir = backend_path
        self.config_path = config_path
        self.config_json = self.load_json(self.config_path)
        self.process = None
        self.vectorlane_size = vectorlane_size

    def get_backend_command(self):
        bin = os.path.join(self.base_dir, "build/bin/Simulator")
        config = os.path.join(self.base_dir, self.config_path)
        cmd = f"{bin} --config {config}"
        return cmd

    def simulation(self, model_path, attribute_path=""):
        def show_progress():
            i = 0
            while not finished:
                i = (i + 1) % 3
                tail = "." * i + " " * (3-i)
                sys.stdout.write("\r[BackendSimulator] Simulation is still running." + tail)
                time.sleep(1)
            print("")
        cmd = f"{self.get_backend_command()} --models_list {model_path}"
        if extension_config.CONFIG_BACKENDSIM_DEBUG_LEVEL:
            cmd += f" --log_level {extension_config.CONFIG_BACKENDSIM_DEBUG_LEVEL}"
        if attribute_path:
            cmd = f"{cmd} --attributes_list {attribute_path}"
        print("[BackendSimulator] cmd> ", cmd)

        # Create progress thread
        finished = False
        progress_thread = threading.Thread(target=show_progress)
        progress_thread.start()
        try:
            result = subprocess.check_output(shlex.split(cmd))
            finished = True
            progress_thread.join()
        except subprocess.CalledProcessError as e:
            finished = True
            progress_thread.join()
            print("[BackendSimulator] Command failed with exit code", e.returncode)
            print("[BackendSimulator] Error output:", e.output)
            assert 0
        result_path = extension_config.CONFIG_BACKEND_RESULT_PATH_KEY
        if result_path is None:
            result_path = os.path.join(os.path.dirname(model_path), "backendsim_result")

        # Save result to result_path
        os.makedirs(result_path, exist_ok=True)
        file_name = str(len(os.listdir(result_path)))
        result_path = os.path.join(result_path, file_name)
        with open(result_path, "w") as f:
            f.write(result.decode())
            print(f'[BackendSimulator] Simulation of "{model_path}" is stored to "{result_path}"')
        return result_path

    def interactive_simulation(self):
        cmd = f"{self.get_backend_command()} --mode interactive"
        if extension_config.CONFIG_BACKENDSIM_DEBUG_LEVEL:
            cmd += f" --log_level {extension_config.CONFIG_BACKENDSIM_DEBUG_LEVEL}"

        print("[BackendSimulator] cmd> ", cmd)
        if self.process is None:
            self.process = subprocess.Popen(
                shlex.split(cmd),
                stdin=subprocess.PIPE,
                stderr=subprocess.PIPE,
                universal_newlines=True
            )
        else:
            print("[BackendSimulator] Simulator is already running.")

    def stop(self):
        if self.process:
            self.process.terminate()
            self.process.wait()
            self.process = None
            print("[BackendSimulator] Simulator stopped.")

    def wait(self):
        if self.process:
            print("[BackendSimulator] Waiting for simulation to complete...")
            self.quit()
            self.process.wait()
            self.process = None
            print("[BackendSimulator] Simulation completed.")

    def send_command(self, command):
        if self.process:
            try:
                if not extension_config.CONFIG_BACKENDSIM_DRYRUN:
                    print(command, flush=True)
                self.process.stdin.write(command + '\n')
                self.process.stdin.flush()
                ret = self.process.stderr.readline().strip()
                return ret
            except BrokenPipeError:
                err = self.process.stderr.readlines()
                for line in err:
                    print(line)
                self.process = None
                exit(1)
        else:
            print("Simulator is not running.")
            return None

    def launch(self, onnx_path, attribute_path, arrival_time=0, partion_id=0):
        command = f"launch {onnx_path} {attribute_path} {arrival_time} {partion_id}"
        ret = self.send_command(command)
        return 0

    def cycle(self):
        ret = self.send_command("cycle")
        return int(ret.split(" ")[-1])

    def until(self, until_cycle):
        command = f"until {until_cycle}"
        ret = self.send_command(command)
        bitmap = int(ret.split(" ")[-1])
        indices = []
        for i in range(64):
            if (bitmap >> i) & 1:
                indices.append(i)
        return indices

    def quit(self):
        command = "quit"
        ret = self.send_command(command)
        return

    def create_attribute_file(self, attribute_path, inputs, **kwargs):
        address_info = {}
        json_content = {}
        os.makedirs(attribute_path, exist_ok=True)
        index = str(len(os.listdir(attribute_path)))
        attribute_path = os.path.join(attribute_path, index)

        for idx, tensor in enumerate(inputs):
            address_info[f"arg{idx}"] = tensor.data_ptr()
        json_content["address_info"] = address_info

        with open(attribute_path, "w") as f:
            json.dump(json_content, f, indent=4)
        return attribute_path

    def load_json(self, config_path):
        config_path = Path(config_path)
        if not config_path.is_file():
            raise FileNotFoundError(f"JSON file not found: {config_path}")

        try:
            with open(config_path, "r") as file:
                data = json.load(file)
                return data
        except json.JSONDecodeError as e:
            raise ValueError(f"Invalid JSON format: {e}")

    def get_core_freq(self):
        if "core_freq" in self.config_json:
            return self.config_json["core_freq"] * 1000 * 1000 # MHz
        else:
            raise KeyError("Key 'core_freq' not found in JSON.")

    def find_zero_sub_tensors(self, tensor):
        x, y = self.vectorlane_size, self.vectorlane_size
        zero_positions = {}

        # Need to set vectorlane size
        if self.vectorlane_size == -1:
            return zero_positions

        for i in range(0, tensor.shape[0], y):
            for j in range(0, tensor.shape[1], x):
                sub_tensor = tensor[i:i + y, j:j + x]
                if np.all(sub_tensor == 0):
                    if i not in zero_positions:
                        zero_positions[i] = {}
                    zero_positions[i][j] = 0 # i pos : j pos : 0
        return zero_positions

    @staticmethod
    def get_result_from_file(result_path):
        core_metrics = {}
        dram_channel_bw = {}
        avg_dram_bw = None
        simulation_time = None

        # Read and find total stat position
        with open(result_path, "r") as f:
            lines = f.readlines()

        simulation_finished_idx = -1
        simulation_finished = False
        for idx, line in enumerate(lines):
            if BackendSimulator.FINISH_STR in line:
                simulation_finished = True
                simulation_finished_idx = idx
                break

        if simulation_finished_idx == -1:
            print("[BackendSimulator] Treid to parsing wrong formated output file!")
            return core_metrics, dram_channel_bw, avg_dram_bw, simulation_time

        total_stat_lines = lines[simulation_finished_idx:]

        for line in total_stat_lines:
            # Parse core metrics (MatMul active cycle, Vector active cycle, etc.)
            if 'Core' in line:
                if 'MatMul active cycle' in line:
                    matmul_cycle = re.search(r'MatMul active cycle (\d+)', line).group(1)
                    vector_cycle = re.search(r'Vector active cycle (\d+)', line).group(1)
                    core_metrics['MatMul_active_cycle'] = int(matmul_cycle)
                    core_metrics['Vector_active_cycle'] = int(vector_cycle)
                elif 'Systolic Array Utilization' in line:
                    systolic_util = re.search(r'Systolic Array Utilization\(%\) (\d+\.?\d*)', line).group(1)
                    vector_util = re.search(r'Vector Unit Utilization\(%\) (\d+\.?\d*)', line).group(1)
                    total_cycle = re.search(r'Total cycle: (\d+)', line).group(1)
                    core_metrics['Systolic_Array_Utilization'] = float(systolic_util)
                    core_metrics['Vector_Unit_Utilization'] = float(vector_util)
                    core_metrics['Total_cycle'] = int(total_cycle)

            # Parse DRAM channel bandwidth utilization
            if 'DRAM CH' in line:
                channel = re.search(r'DRAM CH\[(\d+)\]', line).group(1)
                bw_util = re.search(r'AVG BW Util (\d+\.?\d*)%', line).group(1)
                dram_channel_bw[f'CH[{channel}]'] = float(bw_util)

            # Parse average DRAM bandwidth
            if 'DRAM: AVG BW Util' in line:
                avg_dram_bw = float(re.search(r'AVG BW Util (\d+\.?\d*)%', line).group(1))

            # Parse total simulation time
            if 'Simulation time' in line:
                simulation_time = float(re.search(r'Simulation time: (\d+\.?\d*) seconds', line).group(1))
        return core_metrics, dram_channel_bw, avg_dram_bw, simulation_time

if __name__ == "__main__":
    sim = BackendSimulator("/workspace/PyTorchSim/PyTorchSimBackend", "/workspace/PyTorchSim/PyTorchSimBackend/configs/systolic_ws_128x128_c4_simple_noc_tpuv4.json")
    sim.interactive_simulation()
    sim.until(4000)