import torch
import torch._dynamo
import torch.utils.cpp_extension

def test_result(name, out, cpu_out, rtol=1e-4, atol=1e-4):
    message = f"|{name} Test Passed|"
    if torch.allclose(out.cpu(), cpu_out, rtol=rtol, atol=atol):
        print("-" * len(message))
        print(message)
        print("-" * len(message))
    else:
        print("custom out: ", out.cpu())
        print("cpu out: ", cpu_out)
        exit(1)

def test_maxpool(device):
    torch.manual_seed(0)
    model = nn.MaxPool2d(kernel_size=3, stride=2, padding=1).eval()
    model.to(device=device)
    input = torch.randn(1, 8, 64, 64).to(device=device)
    x1 = input.to(device=device)
    x2 = input.to("cpu")
    opt_fn = torch.compile(dynamic=False)(model)
    res = opt_fn(x1)
    model.to("cpu")
    out = model(x2)
    # test_result("Maxpool Forward", res, out) # TODO: MaxPool Functionality is not working

def test_avgpool(device):
    def avgpool(a):
        return nn.AdaptiveAvgPool2d((1, 1))(a)
    torch.manual_seed(0)
    input = torch.randn(1, 16, 64, 64).to(device=device) #FIXME: channel 8 does not work (range padding issue)
    x1 = input.to(device=device)
    x2 = input.to("cpu")
    opt_fn = torch.compile(dynamic=False)(avgpool)
    res = opt_fn(x1)
    out = avgpool(x2)
    test_result("Avgpool Forward", res, out)

if __name__ == "__main__":
    import os
    import sys
    sys.path.append(os.path.abspath("/workspace/PyTorchSim"))

    from Scheduler.scheduler import ExecutionEngine
    module = ExecutionEngine.setup_device()
    device = module.custom_device()
    test_maxpool(device)
    test_avgpool(device)
